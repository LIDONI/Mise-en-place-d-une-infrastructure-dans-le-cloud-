# Redpanda Ticket Streaming Pipeline

![Python](https://img.shields.io/badge/Python-3.9+-blue?logo=python)
![PySpark](https://img.shields.io/badge/PySpark-4.0+-orange?logo=apache-spark)
[![D√©mo LinkedIn](https://img.shields.io/badge/D√©mo-LinkedIn-blue?logo=linkedin)](https://www.linkedin.com/in/khalid-ouro-adoyi/)

**Cette application illustre une pipeline ETL en temps r√©el utilisant :**

- Python + Confluent Kafka/Redpanda pour g√©n√©rer et publier des tickets clients al√©atoires.

- Apache Spark Streaming pour consommer, parser et traiter ces tickets en continu.

- Sorties multiples : affichage en console et sauvegarde en fichiers JSON avec checkpoint.

Elle repr√©sente un exemple complet de streaming ETL pour monitoring, reporting ou analytics en temps r√©el.

## Sch√©mas de l'Infrastructure 

![Sch√©ma de l‚Äôinfrastructure](images/Image1.png)

- Python 3

- PySpark 4.0+

- Redpanda ou Kafka en local (port par d√©faut utilis√© : 19092)

- Librairies Python : pip install confluent-kafka pyspark

- Dossiers pour la sortie JSON 


## **Installation des d√©pendances :**

`pip install -r requirements.txt`


(optionnel : cr√©er un requirements.txt avec confluent-kafka et pyspark)

## Ex√©cution

1. Lancer Redpanda / Kafka

Si vous utilisez Redpanda en local :

`rpk start`

2. Lancer le producteur de tickets

`python produer_tickets.py`


- Envoie un ticket JSON toutes les secondes dans le topic client_tickets.

3. Lancer Spark Streaming

`spark-submit spark_streaming_processor.py`


- Affiche les tickets en console.

- Sauvegarde √©galement les tickets dans /data/output.

## Structure du projet

‚îú‚îÄ‚îÄ produer_tickets.py         # Producteur Kafka / Redpanda
‚îú‚îÄ‚îÄ spark_streaming_processor.py  # Traitement Spark Streaming
‚îú‚îÄ‚îÄ requirements.txt           # D√©pendances Python
‚îú‚îÄ‚îÄ README.md                  # Documentation
‚îú‚îÄ‚îÄ /data/output               # Fichiers JSON g√©n√©r√©s
‚îî‚îÄ‚îÄ /data/checkpoints          # Checkpoints Spark

# **Flux de donn√©es (Pipeline ETL)**

![Sch√©ma de l‚Äôinfrastructure](images/Image2.png)

- **Extraction :** Produits par produer_tickets.py, envoy√©s au topic client_tickets.

- **Transformation :** Spark Streaming lit les messages, parse le JSON et transforme en DataFrame.

- **Chargement :** Les donn√©es sont envoy√©es vers :

- **La console** pour visualisation en temps r√©el.

- **Des fichiers JSON** sur disque avec checkpointing pour tol√©rance aux pannes.

## Auteur

üë§ Khalid OURO-ADOYI

(**Data Analyst & Data Engineer**) 

Email : khalidouroadoyi@gmail.com

LinkedIn :https://www.linkedin.com/in/khalid-ouro-adoyi/

GitHub :https://github.com/LIDONI